[
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Research Summary",
    "section": "2.1 Background",
    "text": "2.1 Background\nError detection and response times are crucial components in automated operations. This study compares two fundamental approaches:\n\nPlanned Autonomy: Systematic monitoring, preventive error checking, and response-based error handling triggered by system anomalies in a visible preplanned flight path.\nReactive Autonomy: Systematic monitoring, preventive error checking, and response-based error handling triggered by system anomalies in a non-visible autonomous flight path."
  },
  {
    "objectID": "index.html#research-question",
    "href": "index.html#research-question",
    "title": "Human Error in Planned vs Reactive Drone Autonomy Missions",
    "section": "1.2 Research Question",
    "text": "1.2 Research Question\nState your primary research question(s) and hypotheses clearly."
  },
  {
    "objectID": "index.html#data-collection",
    "href": "index.html#data-collection",
    "title": "Research Summary",
    "section": "3.1 Data Collection",
    "text": "3.1 Data Collection\nData was collected through simulated error scenarios across multiple instances and error types. Participants from various age groups interacted with both planned and reactive detection systems."
  },
  {
    "objectID": "index.html#analysis",
    "href": "index.html#analysis",
    "title": "Human Error in Planned vs Reactive Drone Autonomy Missions",
    "section": "2.2 Analysis",
    "text": "2.2 Analysis\nExplain your analytical approach and any statistical methods used."
  },
  {
    "objectID": "index.html#key-findings",
    "href": "index.html#key-findings",
    "title": "Human Error in Planned vs Reactive Drone Autonomy Missions",
    "section": "4.1 Key Findings",
    "text": "4.1 Key Findings\nSummarize and interpret your main results."
  },
  {
    "objectID": "index.html#limitations",
    "href": "index.html#limitations",
    "title": "Human Error in Planned vs Reactive Drone Autonomy Missions",
    "section": "Limitations",
    "text": "Limitations\nDiscuss any limitations or potential sources of bias in your study."
  },
  {
    "objectID": "index.html#future-research",
    "href": "index.html#future-research",
    "title": "Research Summary",
    "section": "5.2 Future Research",
    "text": "5.2 Future Research\nFurther investigation could explore:\n\nLong-term effectiveness of each approach\nIntegration of hybrid detection methods\nOptimization strategies for specific error types"
  },
  {
    "objectID": "index.html#research-questions",
    "href": "index.html#research-questions",
    "title": "Research Summary",
    "section": "2.2 Research Questions",
    "text": "2.2 Research Questions\n\nHow do response times differ between planned and reactive autonomy error detection scenarios?\nWhat impact does user age have on error detection effectiveness?\nWhich error types are most commonly handled in each scenario?"
  },
  {
    "objectID": "index.html#analysis-framework",
    "href": "index.html#analysis-framework",
    "title": "Research Summary",
    "section": "3.2 Analysis Framework",
    "text": "3.2 Analysis Framework\nOur analysis focuses on three key metrics:\n\nError detection rates (caught vs.Â missed)\nFalse positive occurrences\nResponse time distributions\nComparison of average response time\n\nFor detailed visualizations and analysis of the results, please see the Experiment Results section."
  },
  {
    "objectID": "index.html#implications",
    "href": "index.html#implications",
    "title": "Research Summary",
    "section": "5.1 Implications",
    "text": "5.1 Implications\nThe findings suggest important considerations for implementing error detection systems:\n\n[Key implication 1]\n[Key implication 2]\n[Key implication 3]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Research Summary",
    "section": "",
    "text": "This research investigates the impact of planned versus reactive autonomy and their effects on error detection results in automated drone systems. We analyze response times, detection accuracy, and age-related performance variations across different error types including camera, flight, and hardware errors."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Planned vs Reactive Experiment Results",
    "section": "",
    "text": "This section shows the distribution of errors by type and age group.\n\nPlanned ModeReactive Mode"
  },
  {
    "objectID": "analysis_test.html",
    "href": "analysis_test.html",
    "title": "Planned vs Reactive Experiment Results",
    "section": "",
    "text": "Code\nimport json\nimport glob\nimport os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, date\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nAGE_GROUPS = {\n    0: \"Unknown\",\n    1: \"12-17\",\n    2: \"18-24\",\n    3: \"25-34\",\n    4: \"35-44\",\n    5: \"45-54\",\n    6: \"55-64\",\n    7: \"65+\"\n}\n\n\ndef get_age_label(age_code):\n    \"\"\"Convert age code to descriptive label\"\"\"\n    return AGE_GROUPS.get(age_code, f\"Unknown({age_code})\")\n\n\ndef process_json_files(file_pattern='*.json'):\n    \"\"\"\n    Process multiple JSON files and combine their data into a DataFrame.\n    \"\"\"\n    all_error_data = []\n    all_reactive_data = []\n    false_positives_data = []\n    \n    # Construct the path to the data directory\n    data_dir = os.path.join('test_data', file_pattern)\n    # data_dir = os.path.join('data', file_pattern)\n    \n    counter = 0\n\n    for filename in glob.glob(data_dir):\n        counter += 1\n        try:\n            with open(filename, 'r') as f:\n                # Read the file content\n                file_content = f.read()\n                \n                # Split the content into separate JSON objects\n                json_objects = []\n                current_json = \"\"\n                depth = 0\n                \n                for char in file_content:\n                    current_json += char\n                    if char == '{':\n                        depth += 1\n                    elif char == '}':\n                        depth -= 1\n                        if depth == 0 and current_json.strip():\n                            try:\n                                json_obj = json.loads(current_json.strip())\n                                json_objects.append(json_obj)\n                                current_json = \"\"\n                            except json.JSONDecodeError:\n                                pass\n                \n                # Process the main data object\n                main_data = next((obj for obj in json_objects if 'results' in obj), None)\n                if main_data:\n                    # Extract user info\n                    user_info = main_data.get('userinfo', {})\n                    user_age = user_info.get('age', 0)\n                    \n                    # Handle reactive results if present\n                    if 'reactive_results' in main_data:\n                        reactive_row = {\n                            'filename': filename,\n                            'age': user_age,\n                            **main_data.get('reactive_results', {}).get('ObjectsMissed', {})\n                        }\n                        all_reactive_data.append(reactive_row)\n                    \n                    # Process main results\n                    results = main_data.get('results', {})\n                    for error_type, error_data in results.items():\n                        for instance_num, instance_data in error_data.items():\n                            row = {\n                                'error_type': error_type,\n                                'instance': int(instance_num),\n                                'missed': instance_data['missed'],\n                                'time': instance_data['time'],\n                                'filename': filename,\n                                'age': user_age\n                            }\n                            all_error_data.append(row)\n                \n                # Process false positives data\n                fp_obj = next((obj for obj in json_objects if 'FalsePositives' in obj), None)\n                if fp_obj:\n                    fp_data = fp_obj.get('FalsePositives', {})\n                    for error_type, count in fp_data.items():\n                        false_positives_data.append({\n                            'error_type': error_type,\n                            'count': count,\n                            'filename': filename,\n                            'age': user_age\n                        })\n        except Exception as e:\n            print(f\"Error processing file {filename}: {e}\")\n            continue\n\n    # Create DataFrames with default columns even if empty\n    error_df = pd.DataFrame(all_error_data) if all_error_data else pd.DataFrame(\n        columns=['error_type', 'instance', 'missed', 'time', 'filename', 'age'])\n    reactive_df = pd.DataFrame(all_reactive_data) if all_reactive_data else pd.DataFrame(\n        columns=['filename', 'age', 'rows', 'structures'])\n    false_positives_df = pd.DataFrame(false_positives_data) if false_positives_data else pd.DataFrame(\n        columns=['error_type', 'count', 'filename', 'age'])\n    \n    return error_df, reactive_df, false_positives_df, counter\n\n\ndef create_interactive_visualization(error_df, false_positives_df, type):\n    \"\"\"\n    Create interactive Plotly visualization with stacked bar plots for each error type.\n    \"\"\"\n    error_types = ['CameraError', 'FlightError', 'HardwareError']\n    age_groups = sorted(error_df['age'].unique())\n    colors = {'caught': 'lightgreen', 'missed': 'lightcoral', 'false_positives': 'lightskyblue'}\n    \n    # Create subplots with consistent width\n    fig = make_subplots(\n        rows=1, \n        cols=3, \n        subplot_titles=error_types,\n        horizontal_spacing=0.1\n    )\n    \n    # Keep track of trace indices\n    total_traces = []\n    age_group_traces = []\n    \n    # Create base traces (aggregated view)\n    for i, error_type in enumerate(error_types, 1):\n        error_data = error_df[error_df['error_type'] == error_type]\n        fp_data = false_positives_df[false_positives_df['error_type'] == error_type]\n        \n        # Calculate aggregated values\n        total_caught = (~error_data['missed']).sum()\n        total_missed = error_data['missed'].sum()\n        total_fp = fp_data['count'].sum()\n        \n        # Add traces for aggregated view\n        fig.add_trace(\n            go.Bar(\n                x=['All Ages'],\n                y=[total_caught],\n                name='Caught' if i == 1 else None,\n                marker_color=colors['caught'],\n                showlegend=i == 1,\n                legendgroup='caught',\n                hovertemplate='Caught: %{y}&lt;br&gt;Error Type: ' + error_type + '&lt;extra&gt;&lt;/extra&gt;',\n            ),\n            row=1, col=i\n        )\n        total_traces.append(len(fig.data) - 1)\n        \n        fig.add_trace(\n            go.Bar(\n                x=['All Ages'],\n                y=[total_missed],\n                name='Missed' if i == 1 else None,\n                marker_color=colors['missed'],\n                showlegend=i == 1,\n                legendgroup='missed',\n                hovertemplate='Missed: %{y}&lt;br&gt;Error Type: ' + error_type + '&lt;extra&gt;&lt;/extra&gt;',\n            ),\n            row=1, col=i\n        )\n        total_traces.append(len(fig.data) - 1)\n        \n        fig.add_trace(\n            go.Bar(\n                x=['All Ages'],\n                y=[total_fp],\n                name='False Positives' if i == 1 else None,\n                marker_color=colors['false_positives'],\n                showlegend=i == 1,\n                legendgroup='false_positives',\n                hovertemplate='False Positives: %{y}&lt;br&gt;Error Type: ' + error_type + '&lt;extra&gt;&lt;/extra&gt;',\n            ),\n            row=1, col=i\n        )\n        total_traces.append(len(fig.data) - 1)\n        \n        # Add age group traces (initially hidden)\n        for age_code in age_groups:\n            age_label = get_age_label(age_code)\n            age_data = error_data[error_data['age'] == age_code]\n            age_fp = fp_data[fp_data['age'] == age_code]\n            \n            # Calculate values\n            caught = (~age_data['missed']).sum()\n            missed = age_data['missed'].sum()\n            fp_count = age_fp['count'].sum() if not age_fp.empty else 0\n            \n            fig.add_trace(\n                go.Bar(\n                    x=[age_label],\n                    y=[caught],\n                    name='Caught',\n                    marker_color=colors['caught'],\n                    showlegend=False,\n                    visible=False,\n                    legendgroup='caught',\n                    hovertemplate=f'{age_label}&lt;br&gt;Caught: %{{y}}&lt;extra&gt;&lt;/extra&gt;',\n                ),\n                row=1, col=i\n            )\n            age_group_traces.append(len(fig.data) - 1)\n            \n            fig.add_trace(\n                go.Bar(\n                    x=[age_label],\n                    y=[missed],\n                    name='Missed',\n                    marker_color=colors['missed'],\n                    showlegend=False,\n                    visible=False,\n                    legendgroup='missed',\n                    hovertemplate=f'{age_label}&lt;br&gt;Missed: %{{y}}&lt;extra&gt;&lt;/extra&gt;',\n                ),\n                row=1, col=i\n            )\n            age_group_traces.append(len(fig.data) - 1)\n            \n            fig.add_trace(\n                go.Bar(\n                    x=[age_label],\n                    y=[fp_count],\n                    name='False Positives',\n                    marker_color=colors['false_positives'],\n                    showlegend=False,\n                    visible=False,\n                    legendgroup='false_positives',\n                    hovertemplate=f'{age_label}&lt;br&gt;False Positives: %{{y}}&lt;extra&gt;&lt;/extra&gt;',\n                ),\n                row=1, col=i\n            )\n            age_group_traces.append(len(fig.data) - 1)\n\n    # Add buttons for age group selection\n    buttons = [\n        dict(\n            args=[{\n                'visible': [i in total_traces for i in range(len(fig.data))]\n            }],\n            label=\"All Ages\",\n            method=\"restyle\"\n        )\n    ]\n    \n    # Add button for each age group\n    for idx, age_code in enumerate(age_groups):\n        age_label = get_age_label(age_code)\n        age_visibility = []\n        for i in range(len(fig.data)):\n            subplot_idx = i // (3 * (len(age_groups) + 1))\n            is_age_trace = (i - (subplot_idx * 3 * (len(age_groups) + 1)) - 3) // 3 == idx\n            age_visibility.append(is_age_trace)\n        \n        buttons.append(dict(\n            args=[{'visible': age_visibility}],\n            label=age_label,\n            method=\"restyle\"\n        ))\n\n    # Update layout\n    fig.update_layout(\n        barmode='stack',\n        title_text=f\"{type.capitalize()} Mode: Error Distribution by Type and Age Group\",\n        height=500,\n        width=1000,\n        showlegend=True,\n        legend_title_text=\"Error Categories\",\n        hovermode='x unified',\n        margin=dict(l=50, r=120, t=130, b=50),\n        updatemenus=[dict(\n            buttons=buttons,\n            direction=\"down\",\n            showactive=True,\n            x=1.2,\n            xanchor=\"right\",\n            y=1.1,\n            yanchor=\"bottom\",\n            bgcolor='white',\n            bordercolor='darkgray',\n            font=dict(size=12),\n            pad=dict(r=10, t=10)\n        )],\n        annotations=[\n            dict(\n                text=title,\n                x=x,\n                y=1.025,\n                xref=\"paper\",\n                yref=\"paper\",\n                showarrow=False,\n                font=dict(size=14)\n            )\n            for title, x in zip(error_types, [0.13, 0.5, 0.87])\n        ]\n    )\n\n    # Update axes labels\n    fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n    \n    return fig\n\n\ndef create_interactive_visualization(error_df, false_positives_df, type):\n    \"\"\"\n    Create interactive Plotly visualization with stacked bar plots for each error type.\n    \"\"\"\n    error_types = ['CameraError', 'FlightError', 'HardwareError']\n    age_groups = sorted(error_df['age'].unique())\n    colors = {'caught': 'lightgreen', 'missed': 'lightcoral', 'false_positives': 'lightskyblue'}\n    \n    # Create subplots with consistent width\n    fig = make_subplots(\n        rows=1, \n        cols=3, \n        subplot_titles=error_types,\n        horizontal_spacing=0.1\n    )\n    \n    # Keep track of trace indices\n    total_traces = []\n    age_group_traces = []\n    \n    # Create base traces (aggregated view)\n    for i, error_type in enumerate(error_types, 1):\n        error_data = error_df[error_df['error_type'] == error_type]\n        fp_data = false_positives_df[false_positives_df['error_type'] == error_type]\n        \n        # Calculate aggregated values\n        total_caught = (~error_data['missed']).sum()\n        total_missed = error_data['missed'].sum()\n        total_fp = fp_data['count'].sum()\n        \n        # Add traces for aggregated view\n        fig.add_trace(\n            go.Bar(\n                x=['All Ages'],\n                y=[total_caught],\n                name='Caught' if i == 1 else None,\n                marker_color=colors['caught'],\n                showlegend=i == 1,\n                legendgroup='caught',\n                hovertemplate='Caught: %{y}&lt;br&gt;Error Type: ' + error_type + '&lt;extra&gt;&lt;/extra&gt;',\n            ),\n            row=1, col=i\n        )\n        total_traces.append(len(fig.data) - 1)\n        \n        fig.add_trace(\n            go.Bar(\n                x=['All Ages'],\n                y=[total_missed],\n                name='Missed' if i == 1 else None,\n                marker_color=colors['missed'],\n                showlegend=i == 1,\n                legendgroup='missed',\n                hovertemplate='Missed: %{y}&lt;br&gt;Error Type: ' + error_type + '&lt;extra&gt;&lt;/extra&gt;',\n            ),\n            row=1, col=i\n        )\n        total_traces.append(len(fig.data) - 1)\n        \n        fig.add_trace(\n            go.Bar(\n                x=['All Ages'],\n                y=[total_fp],\n                name='False Positives' if i == 1 else None,\n                marker_color=colors['false_positives'],\n                showlegend=i == 1,\n                legendgroup='false_positives',\n                hovertemplate='False Positives: %{y}&lt;br&gt;Error Type: ' + error_type + '&lt;extra&gt;&lt;/extra&gt;',\n            ),\n            row=1, col=i\n        )\n        total_traces.append(len(fig.data) - 1)\n        \n        # Add age group traces (initially hidden)\n        for age_code in age_groups:\n            age_label = get_age_label(age_code)\n            age_data = error_data[error_data['age'] == age_code]\n            age_fp = fp_data[fp_data['age'] == age_code]\n            \n            # Calculate values\n            caught = (~age_data['missed']).sum()\n            missed = age_data['missed'].sum()\n            fp_count = age_fp['count'].sum() if not age_fp.empty else 0\n            \n            fig.add_trace(\n                go.Bar(\n                    x=[age_label],\n                    y=[caught],\n                    name='Caught',\n                    marker_color=colors['caught'],\n                    showlegend=False,\n                    visible=False,\n                    legendgroup='caught',\n                    hovertemplate=f'{age_label}&lt;br&gt;Caught: %{{y}}&lt;extra&gt;&lt;/extra&gt;',\n                ),\n                row=1, col=i\n            )\n            age_group_traces.append(len(fig.data) - 1)\n            \n            fig.add_trace(\n                go.Bar(\n                    x=[age_label],\n                    y=[missed],\n                    name='Missed',\n                    marker_color=colors['missed'],\n                    showlegend=False,\n                    visible=False,\n                    legendgroup='missed',\n                    hovertemplate=f'{age_label}&lt;br&gt;Missed: %{{y}}&lt;extra&gt;&lt;/extra&gt;',\n                ),\n                row=1, col=i\n            )\n            age_group_traces.append(len(fig.data) - 1)\n            \n            fig.add_trace(\n                go.Bar(\n                    x=[age_label],\n                    y=[fp_count],\n                    name='False Positives',\n                    marker_color=colors['false_positives'],\n                    showlegend=False,\n                    visible=False,\n                    legendgroup='false_positives',\n                    hovertemplate=f'{age_label}&lt;br&gt;False Positives: %{{y}}&lt;extra&gt;&lt;/extra&gt;',\n                ),\n                row=1, col=i\n            )\n            age_group_traces.append(len(fig.data) - 1)\n\n    # Add buttons for age group selection\n    buttons = [\n        dict(\n            args=[{\n                'visible': [i in total_traces for i in range(len(fig.data))]\n            }],\n            label=\"All Ages\",\n            method=\"restyle\"\n        )\n    ]\n    \n    # Add button for each age group\n    for idx, age_code in enumerate(age_groups):\n        age_label = get_age_label(age_code)\n        age_visibility = []\n        for i in range(len(fig.data)):\n            subplot_idx = i // (3 * (len(age_groups) + 1))\n            is_age_trace = (i - (subplot_idx * 3 * (len(age_groups) + 1)) - 3) // 3 == idx\n            age_visibility.append(is_age_trace)\n        \n        buttons.append(dict(\n            args=[{'visible': age_visibility}],\n            label=age_label,\n            method=\"restyle\"\n        ))\n\n    # Update layout\n    fig.update_layout(\n        barmode='stack',\n        title_text=f\"{type.capitalize()} Mode: Error Distribution by Type and Age Group\",\n        height=500,\n        width=1000,\n        showlegend=True,\n        legend_title_text=\"Error Categories\",\n        hovermode='x unified',\n        margin=dict(l=50, r=120, t=130, b=50),\n        updatemenus=[dict(\n            buttons=buttons,\n            direction=\"down\",\n            showactive=True,\n            x=1.2,\n            xanchor=\"right\",\n            y=1.1,\n            yanchor=\"bottom\",\n            bgcolor='white',\n            bordercolor='darkgray',\n            font=dict(size=12),\n            pad=dict(r=10, t=10)\n        )],\n        annotations=[\n            dict(\n                text=title,\n                x=x,\n                y=1.025,\n                xref=\"paper\",\n                yref=\"paper\",\n                showarrow=False,\n                font=dict(size=14)\n            )\n            for title, x in zip(error_types, [0.13, 0.5, 0.87])\n        ]\n    )\n\n    # Update axes labels\n    fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n    \n    return fig\n\n\ndef create_heatmap(error_df, type):\n    \"\"\"\n    Create Plotly heatmap for average error times with YlOrRd color scale and zero minimum.\n    Uses zero values only when no non-zero values exist for a particular \n    instance/error type combination.\n    \"\"\"\n    all_data_matrix = pd.pivot_table(\n        error_df,\n        values='time',\n        index='instance',\n        columns='error_type',\n        aggfunc=lambda x: list(x)\n    )\n    \n    # Create matrix for final values\n    time_matrix = pd.DataFrame(\n        index=all_data_matrix.index,\n        columns=all_data_matrix.columns,\n        dtype=float\n    )\n    \n    # Fill in averages, using non-zero values when available, zero otherwise\n    for idx in all_data_matrix.index:\n        for col in all_data_matrix.columns:\n            values = all_data_matrix.loc[idx, col]\n            non_zero_values = [v for v in values if v &gt; 0]\n            if non_zero_values:\n                time_matrix.loc[idx, col] = np.mean(non_zero_values)\n            else:\n                # If only zeros exist for this cell, use 0\n                time_matrix.loc[idx, col] = 0\n    \n    # print(f\"\\n{type} Mode - Time Matrix Statistics:\")\n    # print(f\"Min value: {time_matrix.values.min()}\")\n    # print(f\"Max value: {time_matrix.values.max()}\")\n    \n    hover_text = np.empty(time_matrix.shape, dtype=object)\n    for i in range(time_matrix.shape[0]):\n        for j in range(time_matrix.shape[1]):\n            values = all_data_matrix.iloc[i, j]\n            non_zero_count = sum(1 for v in values if v &gt; 0)\n            total_count = len(values)\n            if non_zero_count &gt; 0:\n                hover_text[i, j] = f\"Instance: {time_matrix.index[i]}&lt;br&gt;\" \\\n                                 f\"Error Type: {time_matrix.columns[j]}&lt;br&gt;\" \\\n                                 f\"Avg Time: {time_matrix.iloc[i, j]:.2f}&lt;br&gt;\" \\\n                                 f\"(from {non_zero_count} non-zero values)\"\n            else:\n                hover_text[i, j] = f\"Instance: {time_matrix.index[i]}&lt;br&gt;\" \\\n                                 f\"Error Type: {time_matrix.columns[j]}&lt;br&gt;\" \\\n                                 f\"Time: 0 (all {total_count} values were zero)\"\n    \n    fig = go.Figure(data=go.Heatmap(\n        z=time_matrix.values,\n        x=time_matrix.columns,\n        y=time_matrix.index,\n        colorscale='YlOrRd',\n        showscale=True,\n        text=np.round(time_matrix.values, 2),\n        texttemplate='%{text}',\n        textfont={'size': 10},\n        hovertemplate='%{customdata}&lt;extra&gt;&lt;/extra&gt;',\n        customdata=hover_text,\n        zmin=0,  # Set minimum value to 0\n        zmid=time_matrix.values.max() / 2 if time_matrix.values.max() &gt; 0 else 0.5,  # Set midpoint\n        zauto=False  # Disable automatic range\n    ))\n    \n    fig.update_layout(\n        title=f'{type.capitalize()} Mode: Average Error Resolution Time by Instance&lt;br&gt;&lt;sub&gt;*Using non-zero values where available; zero values shown where no non-zero times exist&lt;/sub&gt;',\n        xaxis_title='Error Type',\n        yaxis_title='Instance',\n        height=500,\n        coloraxis_colorbar_title='Time'\n    )\n\n    fig = go.Figure(data=go.Heatmap(\n        z=time_matrix.values,\n        x=time_matrix.columns,\n        y=time_matrix.index,\n        colorscale='YlOrRd',\n        showscale=True,\n        text=np.round(time_matrix.values, 2),\n        texttemplate='%{text}',\n        textfont={'size': 10},\n        hovertemplate='%{customdata}&lt;extra&gt;&lt;/extra&gt;',\n        customdata=hover_text,\n        zmin=0,\n        zmid=time_matrix.values.max() / 2 if time_matrix.values.max() &gt; 0 else 0.5,\n        zauto=False\n    ))\n    \n    fig.update_layout(\n        title=f'{type.capitalize()} Mode: Average Error Resolution Time by Instance&lt;br&gt;&lt;sub&gt;Using non-zero values where available; zero values shown where no non-zero times exist&lt;/sub&gt;',\n        xaxis_title='Error Type',\n        yaxis_title='Instance',\n        height=500,\n        width=1000,  # Set explicit width\n        margin=dict(l=50, r=50, t=100, b=50)\n    )\n    \n    return fig\n\n\ndef create_response_time_histogram(planned_df, reactive_df):\n    \"\"\"\n    Create a combined histogram and line chart comparing planned and reactive response times.\n    \"\"\"\n    # Calculate average response times for non-zero values for both modes\n    error_types = ['CameraError', 'FlightError', 'HardwareError']\n    \n    # Process planned data\n    planned_times = {}\n    for error_type in error_types:\n        times = planned_df[planned_df['error_type'] == error_type]['time']\n        non_zero_times = times[times &gt; 0]\n        planned_times[error_type] = non_zero_times.mean() if len(non_zero_times) &gt; 0 else 0\n\n    # Process reactive data\n    reactive_times = {}\n    for error_type in error_types:\n        times = reactive_df[reactive_df['error_type'] == error_type]['time']\n        non_zero_times = times[times &gt; 0]\n        reactive_times[error_type] = non_zero_times.mean() if len(non_zero_times) &gt; 0 else 0\n\n    # Create figure with secondary y-axis\n    fig = go.Figure()\n\n    # Add bars for planned mode\n    fig.add_trace(\n        go.Bar(\n            name='Planned',\n            x=error_types,\n            y=list(planned_times.values()),\n            text=np.round(list(planned_times.values()), 3),\n            textposition='auto',\n            marker_color='rgba(158,202,225,0.6)',\n            hovertemplate='Planned Mode&lt;br&gt;%{x}: %{y:.3f}s&lt;extra&gt;&lt;/extra&gt;'\n        )\n    )\n\n    # Add bars for reactive mode\n    fig.add_trace(\n        go.Bar(\n            name='Reactive',\n            x=error_types,\n            y=list(reactive_times.values()),\n            text=np.round(list(reactive_times.values()), 3),\n            textposition='auto',\n            marker_color='rgba(94,158,217,0.6)',\n            hovertemplate='Reactive Mode&lt;br&gt;%{x}: %{y:.3f}s&lt;extra&gt;&lt;/extra&gt;'\n        )\n    )\n\n    # Add lines connecting the points\n    fig.add_trace(\n        go.Scatter(\n            name='Planned (trend)',\n            x=error_types,\n            y=list(planned_times.values()),\n            mode='lines+markers',\n            line=dict(color='rgb(58,102,171)', width=2),\n            marker=dict(size=8),\n            hovertemplate='Planned Mode&lt;br&gt;%{x}: %{y:.3f}s&lt;extra&gt;&lt;/extra&gt;'\n        )\n    )\n\n    fig.add_trace(\n        go.Scatter(\n            name='Reactive (trend)',\n            x=error_types,\n            y=list(reactive_times.values()),\n            mode='lines+markers',\n            line=dict(color='rgb(137,59,59)', width=2),\n            marker=dict(size=8),\n            hovertemplate='Reactive Mode&lt;br&gt;%{x}: %{y:.3f}s&lt;extra&gt;&lt;/extra&gt;'\n        )\n    )\n\n    # Update layout\n    fig.update_layout(\n        title='Average Response Time Comparison: Planned vs Reactive',\n        xaxis_title='Error Type',\n        yaxis_title='Average Response Time (seconds)',\n        height=500,\n        width=1000,\n        margin=dict(l=50, r=50, t=100, b=50),\n        barmode='group',\n        hovermode='x unified',\n        legend=dict(\n            orientation=\"h\",\n            yanchor=\"bottom\",\n            y=1.02,\n            xanchor=\"right\",\n            x=1\n        )\n    )\n    \n    return fig\n\n\ndef planned_plot():\n    today = datetime.strftime(datetime.now(), '%d-%m-%Y')\n    error_df, planned_df, false_positives_df, counter = process_json_files('*-planned.json')\n    print(f\"Found {counter} data points as of {today}.\")\n    \n    # Create and display interactive distribution plot\n    dist_fig = create_interactive_visualization(error_df, false_positives_df, 'planned')\n    dist_fig.show()\n    \n    # Create and display heatmap\n    heatmap_fig = create_heatmap(error_df, 'planned')\n    heatmap_fig.show()\n    \n\ndef reactive_plot():\n    today = datetime.strftime(datetime.now(), '%d-%m-%Y')\n    error_df, reactive_df, false_positives_df, counter = process_json_files('*-reactive.json')\n    print(f\"Found {counter} data points as of {today}.\")\n    \n    # Create and display interactive distribution plot\n    dist_fig = create_interactive_visualization(error_df, false_positives_df, 'reactive')\n    dist_fig.show()\n    \n    # Create and display heatmap\n    heatmap_fig = create_heatmap(error_df, 'reactive')\n    heatmap_fig.show()\n\n\ndef create_histogram():\n    \"\"\"\n    Create visualization with both planned and reactive data.\n    \"\"\"\n    today = datetime.strftime(datetime.now(), '%d-%m-%Y')\n    \n    # Process planned data\n    planned_error_df, planned_df, planned_fp_df, planned_counter = process_json_files('*-planned.json')\n    print(f\"Found {planned_counter} planned mode data points as of {today}.\")\n    \n    # Process reactive data\n    reactive_error_df, reactive_df, reactive_fp_df, reactive_counter = process_json_files('*-reactive.json')\n    print(f\"Found {reactive_counter} reactive mode data points as of {today}.\")\n       \n    # Create combined response time visualization\n    response_time_fig = create_response_time_histogram(planned_error_df, reactive_error_df)\n    response_time_fig.show()\n\n\n\nPlannedReactive\n\n\n\n\nCode\nplanned_plot()\ncreate_histogram()\n\n\nFound 11 data points as of 19-02-2025.\n\n\n                                                \n\n\n                                                \n\n\nFound 11 planned mode data points as of 19-02-2025.\nFound 1 reactive mode data points as of 19-02-2025.\n\n\n                                                \n\n\n\n\n\n\nCode\nreactive_plot()\ncreate_histogram()\n\n\nFound 1 data points as of 19-02-2025.\n\n\n                                                \n\n\n                                                \n\n\nFound 11 planned mode data points as of 19-02-2025.\nFound 1 reactive mode data points as of 19-02-2025."
  },
  {
    "objectID": "analysis.html#error-distribution-analysis",
    "href": "analysis.html#error-distribution-analysis",
    "title": "Planned vs Reactive Experiment Results",
    "section": "",
    "text": "This section shows the distribution of errors by type and age group.\n\nPlanned ModeReactive Mode"
  },
  {
    "objectID": "analysis.html#success-rate-analysis",
    "href": "analysis.html#success-rate-analysis",
    "title": "Planned vs Reactive Experiment Results",
    "section": "Success Rate Analysis",
    "text": "Success Rate Analysis\nThis section shows the percentage of successful error detections per instance.\n\nPlanned ModeReactive Mode"
  },
  {
    "objectID": "analysis.html#response-time-analysis",
    "href": "analysis.html#response-time-analysis",
    "title": "Planned vs Reactive Experiment Results",
    "section": "Response Time Analysis",
    "text": "Response Time Analysis\nThis section shows the average error resolution time by instance.\n\nPlanned ModeReactive Mode"
  },
  {
    "objectID": "analysis.html#mode-comparison",
    "href": "analysis.html#mode-comparison",
    "title": "Planned vs Reactive Experiment Results",
    "section": "Mode Comparison",
    "text": "Mode Comparison\nThis section directly compares average response times between Planned and Reactive modes."
  }
]